{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6449bf35-701c-4c0e-ab28-5d831ce6bb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.6.3)\n",
      "Requirement already satisfied: transformers in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: datasets in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: emojis in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: multiprocess in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib transformers datasets emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b460f392-cd21-47ab-b8be-2a94490c0198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import emojis\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb01e50b-5140-4531-8677-6e5184d06bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tamilmixsentiment (/home/studio-lab-user/.cache/huggingface/datasets/tamilmixsentiment/default/0.0.0/887420eecaf868ac6c10990649e49d10467e4cd4dffb98a6f20e4fe7c58df390)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366f0f0d5ff048ec8cc7093a02d9f668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/studio-lab-user/.cache/huggingface/datasets/tamilmixsentiment/default/0.0.0/887420eecaf868ac6c10990649e49d10467e4cd4dffb98a6f20e4fe7c58df390/cache-e0dc15cb3461e70b.arrow\n",
      "Loading cached shuffled indices for dataset at /home/studio-lab-user/.cache/huggingface/datasets/tamilmixsentiment/default/0.0.0/887420eecaf868ac6c10990649e49d10467e4cd4dffb98a6f20e4fe7c58df390/cache-ef0be8f2bf001be5.arrow\n",
      "Loading cached shuffled indices for dataset at /home/studio-lab-user/.cache/huggingface/datasets/tamilmixsentiment/default/0.0.0/887420eecaf868ac6c10990649e49d10467e4cd4dffb98a6f20e4fe7c58df390/cache-69d2a8d0c35d823e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2267\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 252\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 629\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bgm Vera level.. Yuvan rocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chiyaan Anna  vera level</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semma fulla Rajinism than .....  Semma super</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oruthar mela nenga visawasam katrarukaha innor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petta parak... Kola Kandula iruken. Thalaiva r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>Super I m waiting kannada trailer    .....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>1st tym ungaal ipdi pakro Thala ü§òü§ò</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>Mass la pakka mass thalaivar athiradi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>Bigil movie trailerku 240k dislike podanum unm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>Nan 75 views ah cross panniten....anyone else ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0                          Bgm Vera level.. Yuvan rocks      0\n",
       "1                              Chiyaan Anna  vera level      0\n",
       "2          Semma fulla Rajinism than .....  Semma super      0\n",
       "3     Oruthar mela nenga visawasam katrarukaha innor...      0\n",
       "4     petta parak... Kola Kandula iruken. Thalaiva r...      0\n",
       "...                                                 ...    ...\n",
       "2262         Super I m waiting kannada trailer    .....      1\n",
       "2263                 1st tym ungaal ipdi pakro Thala ü§òü§ò      0\n",
       "2264              Mass la pakka mass thalaivar athiradi      0\n",
       "2265  Bigil movie trailerku 240k dislike podanum unm...      0\n",
       "2266  Nan 75 views ah cross panniten....anyone else ...      0\n",
       "\n",
       "[2267 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "dataset_name = 'tamilmixsentiment'\n",
    "\n",
    "# batch_size, language_model_name = 64, 'distilbert-base-uncased'\n",
    "# batch_size, language_model_name = 8, 'distilbert-base-uncased'  # sagemaker studio lab\n",
    "# batch_size, language_model_name = 32, 'bert-base-multilingual-cased'\n",
    "# batch_size, language_model_name = 16, 'bert-base-multilingual-cased'\n",
    "# batch_size, language_model_name = 32, 'xlm-roberta-large'\n",
    "\n",
    "\n",
    "# DATA\n",
    "# dataset = datasets.load_dataset('emotion')\n",
    "dataset = datasets.load_dataset(dataset_name)\n",
    "\n",
    "dataset = datasets.DatasetDict(\n",
    "    {k: v.shuffle(2023).select(range(int(v.num_rows * 0.2))) for k, v in dataset.items()}\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c4fd86-36be-441d-8435-babb0433c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]']\n",
      "ü§©    23\n",
      "ü§£    23\n",
      "ü§î    20\n",
      "ü§ò    16\n",
      "ü§ó     7\n",
      "ü•∞     4\n",
      "ü§ü     2\n",
      "üß°     2\n",
      "ü§¢     2\n",
      "ü¶Å     2\n",
      "ü§¶     2\n",
      "ü§ë     1\n",
      "ü§´     1\n",
      "ü•≥     1\n",
      "ü§í     1\n",
      "ü¶Ç     1\n",
      "ü§≠     1\n",
      "ü§Æ     1\n",
      "ü§ú     1\n",
      "ü§ß     1\n",
      "ü§û     1\n",
      "ü§ì     1\n",
      "ü§ñ     1\n",
      "ü•Å     1\n",
      "ü§ô     1\n",
      "ü§™     1\n",
      "ü§∑     1\n",
      "dtype: int64\n",
      "['ü§ò']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff32d5c1cb740efa1c0b4feb2251677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6316f2b88b6242949968e1151b9f7ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495fc98f52d1482c9d45f8350d1b24f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2267\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 252\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 629\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOKENS\n",
    "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
    "\n",
    "# the tokenizer is not prepared for emojis\n",
    "print(tokenizer.tokenize('ü§ò'))\n",
    "\n",
    "# here I add emojis as new tokens\n",
    "my_emojis = [list(emojis.get(x)) for x in dataset['train']['text']]\n",
    "my_emojis = [y for x in my_emojis for y in x]\n",
    "print(pd.Series(my_emojis).value_counts())\n",
    "\n",
    "tokenizer.add_tokens(list(set(my_emojis)))\n",
    "\n",
    "print(tokenizer.tokenize('ü§ò'))\n",
    "\n",
    "# now we can generate embeddings for our text\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)\n",
    "dataset_encoded.set_format('torch')\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76dc2cf-3f35-4fbb-bdaa-82bf1dac49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device cuda:0\n",
      "[0.4004051479117562, 2.042632883168847, 2.1967835629961057, 2.8899307435560506, 3.395479310221198]\n",
      "trainer.args.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "num_labels = len(set(dataset['train']['label']))\n",
    "print('num_labels:', num_labels)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    language_model_name, num_labels=num_labels\n",
    ").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print('model.device', model.device)\n",
    "\n",
    "\n",
    "# METRICS\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "    bal = sklearn.metrics.balanced_accuracy_score(labels, preds)\n",
    "    res = {\n",
    "        'accuracy': acc,\n",
    "        'balanced': bal,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    return res\n",
    "\n",
    "\n",
    "# TRAINER\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='resultados',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    disable_tqdm=False,\n",
    "    evaluation_strategy='steps',\n",
    "    # logging_steps=batch_size,\n",
    "    logging_steps=100,\n",
    "    report_to='none',\n",
    ")\n",
    "\n",
    "\n",
    "my_weights = 1 / dataset['train'].to_pandas()['label'].value_counts(normalize=True).sort_index()\n",
    "my_weights = np.log(my_weights)\n",
    "my_weights = my_weights.tolist()\n",
    "print(my_weights)\n",
    "\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get('labels')\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        # loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0]))\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor(my_weights).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded['train'],\n",
    "    eval_dataset=dataset_encoded['validation'],\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset_encoded['train'],\n",
    "#     eval_dataset=dataset_encoded['validation'],\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "print('trainer.args.device:', trainer.args.device, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e699e586-260e-4067-bb03-54181fc31385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2267\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 852\n",
      "  Number of trainable parameters = 66978053\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='852' max='852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [852/852 03:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.636100</td>\n",
       "      <td>1.577620</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.205223</td>\n",
       "      <td>0.102872</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.174603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.596800</td>\n",
       "      <td>1.552196</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.207751</td>\n",
       "      <td>0.526465</td>\n",
       "      <td>0.477084</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.575200</td>\n",
       "      <td>1.533736</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.529525</td>\n",
       "      <td>0.440919</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.516308</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.564200</td>\n",
       "      <td>1.517785</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.490600</td>\n",
       "      <td>1.502843</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.450200</td>\n",
       "      <td>1.485982</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.457300</td>\n",
       "      <td>1.498564</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.442300</td>\n",
       "      <td>1.509822</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.473500</td>\n",
       "      <td>1.517807</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.439169</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.475100</td>\n",
       "      <td>1.529169</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.238980</td>\n",
       "      <td>0.339463</td>\n",
       "      <td>0.475452</td>\n",
       "      <td>0.313492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.500400</td>\n",
       "      <td>1.510004</td>\n",
       "      <td>0.329365</td>\n",
       "      <td>0.204968</td>\n",
       "      <td>0.356032</td>\n",
       "      <td>0.481758</td>\n",
       "      <td>0.329365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.720900</td>\n",
       "      <td>1.462230</td>\n",
       "      <td>0.658730</td>\n",
       "      <td>0.205012</td>\n",
       "      <td>0.538455</td>\n",
       "      <td>0.553450</td>\n",
       "      <td>0.658730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.537300</td>\n",
       "      <td>1.456046</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.244358</td>\n",
       "      <td>0.546308</td>\n",
       "      <td>0.495599</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.586100</td>\n",
       "      <td>1.451708</td>\n",
       "      <td>0.626984</td>\n",
       "      <td>0.262888</td>\n",
       "      <td>0.557197</td>\n",
       "      <td>0.513494</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.514400</td>\n",
       "      <td>1.444411</td>\n",
       "      <td>0.670635</td>\n",
       "      <td>0.318802</td>\n",
       "      <td>0.547247</td>\n",
       "      <td>0.463893</td>\n",
       "      <td>0.670635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.439660</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.317605</td>\n",
       "      <td>0.541895</td>\n",
       "      <td>0.456594</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.458400</td>\n",
       "      <td>1.420249</td>\n",
       "      <td>0.670635</td>\n",
       "      <td>0.318802</td>\n",
       "      <td>0.545239</td>\n",
       "      <td>0.459356</td>\n",
       "      <td>0.670635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.377400</td>\n",
       "      <td>1.401471</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.321963</td>\n",
       "      <td>0.550549</td>\n",
       "      <td>0.489457</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.371900</td>\n",
       "      <td>1.394012</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.383229</td>\n",
       "      <td>0.496548</td>\n",
       "      <td>0.668606</td>\n",
       "      <td>0.488095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.372800</td>\n",
       "      <td>1.406008</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.347312</td>\n",
       "      <td>0.320025</td>\n",
       "      <td>0.556838</td>\n",
       "      <td>0.317460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>1.384398</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.385835</td>\n",
       "      <td>0.524832</td>\n",
       "      <td>0.564132</td>\n",
       "      <td>0.531746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.355600</td>\n",
       "      <td>1.368071</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.363480</td>\n",
       "      <td>0.572554</td>\n",
       "      <td>0.524123</td>\n",
       "      <td>0.630952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.236200</td>\n",
       "      <td>1.367664</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.358689</td>\n",
       "      <td>0.563036</td>\n",
       "      <td>0.520004</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.435600</td>\n",
       "      <td>1.372575</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.378649</td>\n",
       "      <td>0.504852</td>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.507937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.468700</td>\n",
       "      <td>1.365692</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.368935</td>\n",
       "      <td>0.556809</td>\n",
       "      <td>0.534138</td>\n",
       "      <td>0.591270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.501400</td>\n",
       "      <td>1.361451</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.377019</td>\n",
       "      <td>0.503535</td>\n",
       "      <td>0.567042</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.326500</td>\n",
       "      <td>1.358152</td>\n",
       "      <td>0.456349</td>\n",
       "      <td>0.385846</td>\n",
       "      <td>0.485638</td>\n",
       "      <td>0.576057</td>\n",
       "      <td>0.456349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>1.407200</td>\n",
       "      <td>1.347360</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375689</td>\n",
       "      <td>0.559471</td>\n",
       "      <td>0.554433</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.212000</td>\n",
       "      <td>1.349131</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.365010</td>\n",
       "      <td>0.562345</td>\n",
       "      <td>0.526626</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>1.313100</td>\n",
       "      <td>1.352901</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.360652</td>\n",
       "      <td>0.560689</td>\n",
       "      <td>0.522990</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>1.498500</td>\n",
       "      <td>1.346173</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.393021</td>\n",
       "      <td>0.540534</td>\n",
       "      <td>0.562554</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.344472</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.416587</td>\n",
       "      <td>0.483464</td>\n",
       "      <td>0.571911</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>1.482600</td>\n",
       "      <td>1.342790</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.456376</td>\n",
       "      <td>0.458445</td>\n",
       "      <td>0.626450</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.486600</td>\n",
       "      <td>1.328161</td>\n",
       "      <td>0.551587</td>\n",
       "      <td>0.483588</td>\n",
       "      <td>0.562010</td>\n",
       "      <td>0.590796</td>\n",
       "      <td>0.551587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>1.372000</td>\n",
       "      <td>1.325631</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.470836</td>\n",
       "      <td>0.574429</td>\n",
       "      <td>0.582161</td>\n",
       "      <td>0.575397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>1.172500</td>\n",
       "      <td>1.323303</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.469095</td>\n",
       "      <td>0.559177</td>\n",
       "      <td>0.568678</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>1.278300</td>\n",
       "      <td>1.319227</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.464626</td>\n",
       "      <td>0.567958</td>\n",
       "      <td>0.594242</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>1.157400</td>\n",
       "      <td>1.320735</td>\n",
       "      <td>0.551587</td>\n",
       "      <td>0.466922</td>\n",
       "      <td>0.546066</td>\n",
       "      <td>0.580711</td>\n",
       "      <td>0.551587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.303800</td>\n",
       "      <td>1.323300</td>\n",
       "      <td>0.551587</td>\n",
       "      <td>0.473132</td>\n",
       "      <td>0.549311</td>\n",
       "      <td>0.585258</td>\n",
       "      <td>0.551587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>1.395300</td>\n",
       "      <td>1.319213</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.473664</td>\n",
       "      <td>0.593258</td>\n",
       "      <td>0.590039</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>1.345200</td>\n",
       "      <td>1.322836</td>\n",
       "      <td>0.626984</td>\n",
       "      <td>0.456010</td>\n",
       "      <td>0.593945</td>\n",
       "      <td>0.566930</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>1.540900</td>\n",
       "      <td>1.315735</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.478676</td>\n",
       "      <td>0.592231</td>\n",
       "      <td>0.591150</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>1.206200</td>\n",
       "      <td>1.338241</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.598387</td>\n",
       "      <td>0.610007</td>\n",
       "      <td>0.623016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.405100</td>\n",
       "      <td>1.349207</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.441739</td>\n",
       "      <td>0.580501</td>\n",
       "      <td>0.553816</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>1.304600</td>\n",
       "      <td>1.332169</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.485329</td>\n",
       "      <td>0.571833</td>\n",
       "      <td>0.625061</td>\n",
       "      <td>0.559524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>1.221000</td>\n",
       "      <td>1.319065</td>\n",
       "      <td>0.503968</td>\n",
       "      <td>0.497759</td>\n",
       "      <td>0.530982</td>\n",
       "      <td>0.627086</td>\n",
       "      <td>0.503968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>1.360500</td>\n",
       "      <td>1.326043</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.471734</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>0.619449</td>\n",
       "      <td>0.440476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>1.357000</td>\n",
       "      <td>1.321364</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.508871</td>\n",
       "      <td>0.533018</td>\n",
       "      <td>0.606144</td>\n",
       "      <td>0.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.168400</td>\n",
       "      <td>1.320058</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.472921</td>\n",
       "      <td>0.526527</td>\n",
       "      <td>0.579949</td>\n",
       "      <td>0.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>1.340300</td>\n",
       "      <td>1.322725</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.438146</td>\n",
       "      <td>0.575940</td>\n",
       "      <td>0.547408</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>1.305000</td>\n",
       "      <td>1.321602</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.430628</td>\n",
       "      <td>0.576525</td>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>1.315000</td>\n",
       "      <td>1.322954</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.453183</td>\n",
       "      <td>0.574736</td>\n",
       "      <td>0.563387</td>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>1.277700</td>\n",
       "      <td>1.300134</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.464527</td>\n",
       "      <td>0.543848</td>\n",
       "      <td>0.576181</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>1.322422</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.451796</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.582391</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>1.414300</td>\n",
       "      <td>1.319936</td>\n",
       "      <td>0.468254</td>\n",
       "      <td>0.457352</td>\n",
       "      <td>0.477761</td>\n",
       "      <td>0.583659</td>\n",
       "      <td>0.468254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>1.348900</td>\n",
       "      <td>1.301657</td>\n",
       "      <td>0.519841</td>\n",
       "      <td>0.450477</td>\n",
       "      <td>0.524417</td>\n",
       "      <td>0.571840</td>\n",
       "      <td>0.519841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>1.196800</td>\n",
       "      <td>1.310756</td>\n",
       "      <td>0.626984</td>\n",
       "      <td>0.434875</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>1.317718</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.420060</td>\n",
       "      <td>0.573992</td>\n",
       "      <td>0.542792</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.354900</td>\n",
       "      <td>1.310617</td>\n",
       "      <td>0.551587</td>\n",
       "      <td>0.478576</td>\n",
       "      <td>0.560004</td>\n",
       "      <td>0.583625</td>\n",
       "      <td>0.551587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>1.182500</td>\n",
       "      <td>1.307815</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.474983</td>\n",
       "      <td>0.558632</td>\n",
       "      <td>0.595610</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1.263800</td>\n",
       "      <td>1.313470</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.461799</td>\n",
       "      <td>0.553737</td>\n",
       "      <td>0.617395</td>\n",
       "      <td>0.563492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>1.353700</td>\n",
       "      <td>1.311637</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.459836</td>\n",
       "      <td>0.556972</td>\n",
       "      <td>0.610423</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>1.249900</td>\n",
       "      <td>1.302963</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.452650</td>\n",
       "      <td>0.541430</td>\n",
       "      <td>0.568039</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.048500</td>\n",
       "      <td>1.297565</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.464183</td>\n",
       "      <td>0.596734</td>\n",
       "      <td>0.578573</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>1.302734</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.416578</td>\n",
       "      <td>0.562307</td>\n",
       "      <td>0.539039</td>\n",
       "      <td>0.591270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>1.356300</td>\n",
       "      <td>1.299507</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.452318</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>0.567497</td>\n",
       "      <td>0.563492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>1.272900</td>\n",
       "      <td>1.306659</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.455478</td>\n",
       "      <td>0.551901</td>\n",
       "      <td>0.568139</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>1.252700</td>\n",
       "      <td>1.305123</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.490996</td>\n",
       "      <td>0.565067</td>\n",
       "      <td>0.593360</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.155900</td>\n",
       "      <td>1.318128</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.481082</td>\n",
       "      <td>0.562027</td>\n",
       "      <td>0.588307</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>1.284100</td>\n",
       "      <td>1.313771</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.562551</td>\n",
       "      <td>0.585386</td>\n",
       "      <td>0.559524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>1.008000</td>\n",
       "      <td>1.316291</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.455145</td>\n",
       "      <td>0.570930</td>\n",
       "      <td>0.573444</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>1.319700</td>\n",
       "      <td>1.315025</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.576305</td>\n",
       "      <td>0.540706</td>\n",
       "      <td>0.623016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>1.117600</td>\n",
       "      <td>1.308237</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.451331</td>\n",
       "      <td>0.566692</td>\n",
       "      <td>0.539640</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.396600</td>\n",
       "      <td>1.296703</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.451552</td>\n",
       "      <td>0.567368</td>\n",
       "      <td>0.606677</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>1.226300</td>\n",
       "      <td>1.288448</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.469195</td>\n",
       "      <td>0.596564</td>\n",
       "      <td>0.586778</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>1.260800</td>\n",
       "      <td>1.287299</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.478676</td>\n",
       "      <td>0.593830</td>\n",
       "      <td>0.593574</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>1.078300</td>\n",
       "      <td>1.290205</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.464626</td>\n",
       "      <td>0.576030</td>\n",
       "      <td>0.586463</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>1.123400</td>\n",
       "      <td>1.299713</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.560575</td>\n",
       "      <td>0.583764</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.223100</td>\n",
       "      <td>1.296724</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.447960</td>\n",
       "      <td>0.557966</td>\n",
       "      <td>0.568895</td>\n",
       "      <td>0.575397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>1.117800</td>\n",
       "      <td>1.293967</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.469849</td>\n",
       "      <td>0.597083</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>656</td>\n",
       "      <td>1.141700</td>\n",
       "      <td>1.293839</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.468108</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>0.581052</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>1.014800</td>\n",
       "      <td>1.300738</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.451442</td>\n",
       "      <td>0.578412</td>\n",
       "      <td>0.569555</td>\n",
       "      <td>0.591270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>1.045100</td>\n",
       "      <td>1.314581</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.434010</td>\n",
       "      <td>0.571619</td>\n",
       "      <td>0.552773</td>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.220200</td>\n",
       "      <td>1.311053</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.461244</td>\n",
       "      <td>0.584199</td>\n",
       "      <td>0.572453</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>1.024600</td>\n",
       "      <td>1.309411</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.461355</td>\n",
       "      <td>0.577701</td>\n",
       "      <td>0.570795</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>1.321554</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.441417</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.542659</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>1.049100</td>\n",
       "      <td>1.329772</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>0.562784</td>\n",
       "      <td>0.531964</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>1.208200</td>\n",
       "      <td>1.324933</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.445010</td>\n",
       "      <td>0.575431</td>\n",
       "      <td>0.544262</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.126800</td>\n",
       "      <td>1.319575</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.446862</td>\n",
       "      <td>0.580910</td>\n",
       "      <td>0.556249</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>1.254000</td>\n",
       "      <td>1.314632</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.446318</td>\n",
       "      <td>0.579764</td>\n",
       "      <td>0.559518</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>0.952600</td>\n",
       "      <td>1.308068</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.450133</td>\n",
       "      <td>0.579304</td>\n",
       "      <td>0.565114</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>1.099100</td>\n",
       "      <td>1.304415</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.458849</td>\n",
       "      <td>0.582140</td>\n",
       "      <td>0.571673</td>\n",
       "      <td>0.599206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>1.331800</td>\n",
       "      <td>1.303096</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.474318</td>\n",
       "      <td>0.591498</td>\n",
       "      <td>0.584909</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.299767</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.497305</td>\n",
       "      <td>0.600102</td>\n",
       "      <td>0.615672</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>1.125300</td>\n",
       "      <td>1.296581</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.493712</td>\n",
       "      <td>0.592346</td>\n",
       "      <td>0.605564</td>\n",
       "      <td>0.591270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>776</td>\n",
       "      <td>1.248800</td>\n",
       "      <td>1.295661</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.492514</td>\n",
       "      <td>0.589505</td>\n",
       "      <td>0.602356</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>1.297534</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.484342</td>\n",
       "      <td>0.592337</td>\n",
       "      <td>0.599837</td>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>1.213500</td>\n",
       "      <td>1.294959</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.497305</td>\n",
       "      <td>0.601590</td>\n",
       "      <td>0.611164</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.195600</td>\n",
       "      <td>1.293391</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.493712</td>\n",
       "      <td>0.592602</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.591270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>1.105600</td>\n",
       "      <td>1.292395</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.497527</td>\n",
       "      <td>0.588935</td>\n",
       "      <td>0.606903</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.292804</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.496329</td>\n",
       "      <td>0.586049</td>\n",
       "      <td>0.604388</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>1.314000</td>\n",
       "      <td>1.292434</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.496329</td>\n",
       "      <td>0.586049</td>\n",
       "      <td>0.604388</td>\n",
       "      <td>0.579365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>1.155300</td>\n",
       "      <td>1.291857</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.506242</td>\n",
       "      <td>0.589273</td>\n",
       "      <td>0.608509</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.258000</td>\n",
       "      <td>1.291733</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.506242</td>\n",
       "      <td>0.589273</td>\n",
       "      <td>0.608509</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>1.292010</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.507440</td>\n",
       "      <td>0.592465</td>\n",
       "      <td>0.610229</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to resultados/checkpoint-500\n",
      "Configuration saved in resultados/checkpoint-500/config.json\n",
      "Model weights saved in resultados/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in resultados/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in resultados/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 252\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to resultados2\n",
      "Configuration saved in resultados2/config.json\n",
      "Model weights saved in resultados2/pytorch_model.bin\n",
      "tokenizer config file saved in resultados2/tokenizer_config.json\n",
      "Special tokens file saved in resultados2/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# In[13]:\n",
    "trainer.train()\n",
    "trainer.save_model('resultados2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ecfc8e6-b3d1-4903-9120-5b148bca6b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file resultados2/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"resultados2\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30549\n",
      "}\n",
      "\n",
      "loading configuration file resultados2/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"resultados2\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30549\n",
      "}\n",
      "\n",
      "loading weights file resultados2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at resultados2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ean Anna Unaku ena achi ean engala ipdi savade...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.394225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If u like trailer then like</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bc konsa konda ka... Kya? 'NERKONDA' ohhh beti...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.299284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ena da epadi eduthu vechurikinga . vera level ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.351597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maranam mass maranam athuku Makkal selvan ta v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Thala niga vera level love u</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Rajani sir's akshay gi fans put ur like here</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.286796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Neraya neraya neraya......  Thala fans hit like</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Thalaivar eppavum mass than.... ilana soldrava...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Last dialogue  epo ellam may epd than jalra ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  pred      prob\n",
       "0    Ean Anna Unaku ena achi ean engala ipdi savade...      2     1  0.394225\n",
       "1                          If u like trailer then like      0     0  0.271019\n",
       "2    Bc konsa konda ka... Kya? 'NERKONDA' ohhh beti...      3     1  0.299284\n",
       "3    ena da epadi eduthu vechurikinga . vera level ...      0     2  0.351597\n",
       "4    Maranam mass maranam athuku Makkal selvan ta v...      0     0  0.438958\n",
       "..                                                 ...    ...   ...       ...\n",
       "624                       Thala niga vera level love u      0     0  0.692919\n",
       "625       Rajani sir's akshay gi fans put ur like here      0     3  0.286796\n",
       "626    Neraya neraya neraya......  Thala fans hit like      0     0  0.691776\n",
       "627  Thalaivar eppavum mass than.... ilana soldrava...      0     0  0.571014\n",
       "628  Last dialogue  epo ellam may epd than jalra ta...      0     0  0.313017\n",
       "\n",
       "[629 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATION\n",
    "df = dataset['test'].to_pandas()\n",
    "\n",
    "pipe = pipeline('sentiment-analysis', 'resultados2')\n",
    "predictions = pipe(dataset['test']['text'])\n",
    "\n",
    "df[['pred', 'prob']] = pd.DataFrame(predictions).values\n",
    "df['pred'] = df['pred'].str.replace('LABEL_', '').astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48da46fd-72a5-4975-bcea-660b046dd2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     0   1   2   3   4\n",
       "label                     \n",
       "0      262  86  60  11   5\n",
       "1       34  26  22   1   2\n",
       "2       35  21  12   0   2\n",
       "3       18  12   8   0   1\n",
       "4        0   0   0   1  10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df['label'], df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02008519-4bb0-4c64-8217-a8da0202aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[262,  86,  60,  11,   5],\n",
       "       [ 34,  26,  22,   1,   2],\n",
       "       [ 35,  21,  12,   0,   2],\n",
       "       [ 18,  12,   8,   0,   1],\n",
       "       [  0,   0,   0,   1,  10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(df['label'], df['pred'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30adf9ce-9d7a-4559-9a00-40cddc094d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f76a4452fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=dataset['test'].features['label'].names)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378fd66f-035b-44f3-92a9-06b3ced59522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Positive       0.75      0.62      0.68       424\n",
      "      Negative       0.18      0.31      0.23        85\n",
      "Mixed_feelings       0.12      0.17      0.14        70\n",
      " unknown_state       0.00      0.00      0.00        39\n",
      "     not-Tamil       0.50      0.91      0.65        11\n",
      "\n",
      "      accuracy                           0.49       629\n",
      "     macro avg       0.31      0.40      0.34       629\n",
      "  weighted avg       0.55      0.49      0.51       629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(df['label'], df['pred'], target_names=dataset['test'].features['label'].names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
